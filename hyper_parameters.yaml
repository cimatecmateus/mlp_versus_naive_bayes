# Hyperparameters for a MLP with 3 layers: input, hiden, output
hiden_layer_neurons: 32
activation_functions: [tanh, tanh, sigmoid]
dropout_parameters: [False, 0.2, False, 0.8]
loss: sparse_categorical_crossentropy
metrics: [accuracy]
optimizer: Adam
lr: 0.1
batch_size: 10
epochs: 100